{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The TensorFlow notebooks for this project are still in development so may contain bugs and are lacking in documentation. Please see the PyStan notebooks for a clearer walkthrough.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfd = tfp.distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Confirm GPU in use\n",
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "P = 10\n",
    "N = 10 ** 2\n",
    "SEED = 1729"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ground truth\n",
    "np.random.seed(SEED)\n",
    "true_transmission_rate = np.random.beta(2, 10, P)\n",
    "true_occurrence_rate = np.random.beta(2, 10, P)\n",
    "base_rate = np.random.beta(2, 10, 1)\n",
    "\n",
    "test_sensitivity = np.random.beta(4, 3, 1)  # True positive rate\n",
    "test_specificity = np.random.beta(50, 2, 1)  # True negative rate\n",
    "true_lambda = np.hstack([test_sensitivity, test_specificity])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate data\n",
    "data = {}\n",
    "for p in range(P):\n",
    "    occurrence = np.random.binomial(1, true_occurrence_rate[p], N)\n",
    "    transmission = occurrence * np.random.binomial(1, true_transmission_rate[p], N)\n",
    "    data[f'O{p+1}'] = occurrence\n",
    "    data[f'T{p+1}'] = transmission\n",
    "data['T0'] = np.random.binomial(1, base_rate, N)\n",
    "X = pd.DataFrame(data)\n",
    "\n",
    "z = X.loc[:, X.columns.str.startswith('T')].sum(axis=1)\n",
    "X = X.loc[:, X.columns.str.startswith('O')]\n",
    "y = (z > 0).astype(int)\n",
    "\n",
    "# Introducing false positives and negatives\n",
    "y = y * np.random.binomial(1, true_lambda[0], N) + \\\n",
    "    (1 - y) * np.random.binomial(1, (1 - true_lambda[1]), N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to tensors\n",
    "X = tf.convert_to_tensor(X, dtype=tf.float32)\n",
    "y = tf.convert_to_tensor(y, dtype=tf.float32)\n",
    "# Move to GPU\n",
    "X = X + tf.fill(X.shape, 0.0)\n",
    "y = y + tf.fill(y.shape, 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape parameters for test accuracy priors:\n",
      "Alphas:  [83.50230278926166, 7298.251978696008]\n",
      "Betas:  [30.88441336041184, 23.429380348943674]\n"
     ]
    }
   ],
   "source": [
    "# Set antigen test mean and std. error for TP and TN rates (for strong priors)\n",
    "\n",
    "# True positive\n",
    "mean_tp = 0.73000\n",
    "se_tp = 0.04133\n",
    "\n",
    "# True negative\n",
    "mean_tn = 0.99680\n",
    "se_tn = 0.00066\n",
    "\n",
    "mean_rates = [mean_tp, mean_tn]\n",
    "se_rates = [se_tp, se_tn]\n",
    "alphas = []\n",
    "betas = []\n",
    "\n",
    "for i in range(2):\n",
    "    alphas.append((((1 - mean_rates[i])/se_rates[i]**2)-(1/mean_rates[i])) * (mean_rates[i]**2))\n",
    "    betas.append(alphas[i]*((1/mean_rates[i])-1))\n",
    "    \n",
    "print('Shape parameters for test accuracy priors:')    \n",
    "print('Alphas: ', alphas)\n",
    "print('Betas: ', betas)\n",
    "\n",
    "lambda_prior_params = np.array([alphas, betas]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define log-likelihood\n",
    "@tf.function\n",
    "def censored_poisbinom_loglike(theta, rho, lambda_):\n",
    "    target = 0\n",
    "    # Pre-computation\n",
    "    log1m_theta = tf.math.log(1-theta)\n",
    "    log_lambda = tf.math.log(lambda_)\n",
    "    log1m_lambda = tf.math.log(1-lambda_)\n",
    "    # Support\n",
    "    if tf.math.reduce_any(tf.math.logical_or(theta <= 0., theta >= 1.)):\n",
    "        return -np.inf\n",
    "    if tf.math.logical_or(rho <= 0., rho >= 1.):\n",
    "        return -np.inf\n",
    "    if tf.math.reduce_any(lambda_ <= 0.):\n",
    "        return -np.inf\n",
    "    # Priors (beta)\n",
    "    target += (lambda_prior_params[0,0] - 1) * log_lambda[0] + \\\n",
    "              (lambda_prior_params[0,1] - 1) * log1m_lambda[0]\n",
    "    target += (lambda_prior_params[1,0] - 1) * log_lambda[1] + \\\n",
    "              (lambda_prior_params[1,1] - 1) * log1m_lambda[1]\n",
    "    # Likelihood\n",
    "    s = tf.einsum('ij,j->i', X, log1m_theta) + tf.math.log(1-rho)\n",
    "    target += tf.math.reduce_sum(tf.where(\n",
    "        y == 1,\n",
    "        tfp.math.log_add_exp(\n",
    "            tfp.math.log1mexp(s) + log_lambda[0],\n",
    "            s + log1m_lambda[1]\n",
    "        ), \n",
    "        tfp.math.log_add_exp(\n",
    "            s + log_lambda[1],\n",
    "            tfp.math.log1mexp(s) + log1m_lambda[0]\n",
    "        )\n",
    "    ))\n",
    "    return target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define negative log-likelihood and use AD to compute gradients\n",
    "@tf.function\n",
    "def censored_poisbinom_negloglike(params):\n",
    "    theta, rho, lambda_ = tf.split(params, [P, 1, 2], axis=0)\n",
    "    # need to take these back down to vectors and scalars:\n",
    "    theta = tf.reshape(theta,(P,))\n",
    "    rho = tf.reshape(rho,())\n",
    "    lambda_ = tf.reshape(lambda_, (2,))\n",
    "    return -1 * censored_poisbinom_loglike(theta, rho, lambda_)\n",
    "\n",
    "@tf.function\n",
    "def censored_poisbinom_negloglike_and_grad(params):\n",
    "    return tfp.math.value_and_gradient(\n",
    "        censored_poisbinom_negloglike, \n",
    "        params\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Approximate MLE using gradient descent\n",
    "start = tf.fill(P + 3, 0.5)\n",
    "\n",
    "optim_results = tfp.optimizer.bfgs_minimize(\n",
    "    censored_poisbinom_negloglike_and_grad, start, tolerance=1e-8\n",
    ")\n",
    "\n",
    "est_params = optim_results.position.numpy()\n",
    "est_serr = np.sqrt(np.diagonal(optim_results.inverse_hessian_estimate.numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set model parameters\n",
    "nuts_samples = 1000\n",
    "nuts_burnin = 200\n",
    "init_step_size=.3\n",
    "init = [est_params[:P], est_params[P], est_params[P+1:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73.33 seconds elapsed\n"
     ]
    }
   ],
   "source": [
    "# Fit model\n",
    "@tf.function\n",
    "def nuts_sampler(init):\n",
    "    nuts_kernel = tfp.mcmc.NoUTurnSampler(\n",
    "        target_log_prob_fn=censored_poisbinom_loglike, \n",
    "        step_size=init_step_size,\n",
    "    )\n",
    "    adapt_nuts_kernel = tfp.mcmc.DualAveragingStepSizeAdaptation(\n",
    "        inner_kernel=nuts_kernel,\n",
    "        num_adaptation_steps=nuts_burnin,\n",
    "        step_size_getter_fn=lambda pkr: pkr.step_size,\n",
    "        log_accept_prob_getter_fn=lambda pkr: pkr.log_accept_ratio,\n",
    "        step_size_setter_fn=lambda pkr, new_step_size: pkr._replace(step_size=new_step_size)\n",
    "    )\n",
    "\n",
    "    samples = tfp.mcmc.sample_chain(\n",
    "        num_results=nuts_samples,\n",
    "        current_state=init,\n",
    "        kernel=adapt_nuts_kernel,\n",
    "        num_burnin_steps=nuts_burnin,\n",
    "        parallel_iterations=10,\n",
    "        trace_fn=None\n",
    "    )\n",
    "    return samples\n",
    "\n",
    "start = time.time()\n",
    "samples = nuts_sampler(init)\n",
    "print(f\"{time.time() - start:.02f} seconds elapsed\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorFlow (GPU)",
   "language": "python",
   "name": "tf-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
