{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The TensorFlow notebooks for this project are still in development so may contain bugs and are lacking in documentation. Please see the PyStan notebooks for a clearer walkthrough.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfd = tfp.distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Confirm GPU in use\n",
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "P = 10\n",
    "S = 10 ** 2 # Total population\n",
    "NA = 30 # Number of surveys\n",
    "SEED = 1729"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ground truth\n",
    "np.random.seed(SEED)\n",
    "true_transmission_rate = np.random.beta(2, 10, P)\n",
    "true_occurrence_rate = np.random.beta(2, 10, P)\n",
    "base_rate = np.random.beta(2, 10, 1)\n",
    "\n",
    "t_i = np.random.beta(8, 2, 1)  # Prob(tested | infected)\n",
    "t_not_i = np.random.beta(2, 20, 1)  # Prob(tested | not-infected)\n",
    "true_gamma = np.hstack([t_i, t_not_i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate data\n",
    "data = {}\n",
    "for p in range(P):\n",
    "    occurrence = np.random.binomial(1, true_occurrence_rate[p], S)\n",
    "    transmission = occurrence * np.random.binomial(1, true_transmission_rate[p], S)\n",
    "    data[f'O{p+1}'] = occurrence\n",
    "    data[f'T{p+1}'] = transmission\n",
    "\n",
    "data['T0'] = np.random.binomial(1, base_rate, S)\n",
    "X = pd.DataFrame(data)\n",
    "z = X.loc[:, X.columns.str.startswith('T')].sum(axis=1)\n",
    "y = (z > 0).astype(int)\n",
    "\n",
    "# Resampling using testing probabilites conditional on infected\n",
    "tested = y*np.random.binomial(1, true_gamma[0], S) + (1-y)*np.random.binomial(1, true_gamma[1], S)\n",
    "y = y[tested == 1]\n",
    "if NA >= (S - y.shape[0]):\n",
    "    X_survey = X[tested == 0].reset_index()\n",
    "else:\n",
    "    X_survey = X[tested == 0].reset_index().sample()\n",
    "X = X[tested == 1].reset_index()\n",
    "\n",
    "N = X.shape[0]\n",
    "NA = X_survey.shape[0]\n",
    "\n",
    "X = X.loc[:, X.columns.str.startswith('O')]\n",
    "X_survey = X_survey.loc[:, X_survey.columns.str.startswith('O')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to tensors\n",
    "X = tf.convert_to_tensor(X, dtype=tf.float32)\n",
    "X_survey = tf.convert_to_tensor(X_survey, dtype=tf.float32)\n",
    "y = tf.convert_to_tensor(y, dtype=tf.float32)\n",
    "# Move to GPU\n",
    "X = X + tf.fill(X.shape, 0.0)\n",
    "X_survey = X_survey + tf.fill(X_survey.shape, 0.0)\n",
    "y = y + tf.fill(y.shape, 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define log-likelihood\n",
    "@tf.function\n",
    "def censored_poisbinom_loglike(theta, rho, gamma):\n",
    "    target = 0\n",
    "    # Pre-computation\n",
    "    log1m_theta = tf.math.log(1-theta)\n",
    "    log_gamma = tf.math.log(gamma)\n",
    "    log1m_gamma = tf.math.log(1-gamma)\n",
    "    # Support\n",
    "    if tf.math.reduce_any(tf.math.logical_or(theta <= 0., theta >= 1.)):\n",
    "        return -np.inf\n",
    "    if tf.math.logical_or(rho <= 0., rho >= 1.):\n",
    "        return -np.inf\n",
    "    if tf.math.reduce_any(tf.math.logical_or(gamma <= 0., gamma >= 1.)):\n",
    "        return -np.inf\n",
    "    # Likelihood (Survey)\n",
    "    s = tf.einsum('ij,j->i', X_survey, log1m_theta) + tf.math.log(1-rho)\n",
    "    target += tf.math.reduce_sum(tfp.math.log_add_exp(\n",
    "            tfp.math.log1mexp(s) + log1m_gamma[0],\n",
    "            s + log1m_gamma[1]\n",
    "    ))\n",
    "    # Likelihood (Tests)\n",
    "    s = tf.einsum('ij,j->i', X, log1m_theta) + tf.math.log(1-rho)\n",
    "    target += tf.math.reduce_sum(tf.where(\n",
    "        y == 1,\n",
    "        tfp.math.log1mexp(s) + log_gamma[0], \n",
    "        s + log_gamma[1]\n",
    "    ))\n",
    "    return target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define negative log-likelihood and use AD to compute gradients\n",
    "@tf.function\n",
    "def censored_poisbinom_negloglike(params):\n",
    "    theta, rho, gamma = tf.split(params, [P, 1, 2], axis=0)\n",
    "    # need to take these back down to vectors and scalars:\n",
    "    theta = tf.reshape(theta,(P,))\n",
    "    rho = tf.reshape(rho,())\n",
    "    gamma = tf.reshape(gamma, (2,))\n",
    "    return -1 * censored_poisbinom_loglike(theta, rho, gamma)\n",
    "\n",
    "@tf.function\n",
    "def censored_poisbinom_negloglike_and_grad(params):\n",
    "    return tfp.math.value_and_gradient(\n",
    "        censored_poisbinom_negloglike, \n",
    "        params\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Approximate MLE using gradient descent\n",
    "start = tf.fill(P + 3, 0.5)\n",
    "\n",
    "optim_results = tfp.optimizer.bfgs_minimize(\n",
    "    censored_poisbinom_negloglike_and_grad, start, tolerance=1e-8\n",
    ")\n",
    "\n",
    "est_params = optim_results.position.numpy()\n",
    "est_serr = np.sqrt(np.diagonal(optim_results.inverse_hessian_estimate.numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set model parameters\n",
    "nuts_samples = 1000\n",
    "nuts_burnin = 200\n",
    "init_step_size=.3\n",
    "init = [est_params[:P], est_params[P], est_params[P+1:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.84 seconds elapsed\n"
     ]
    }
   ],
   "source": [
    "# Fit model\n",
    "@tf.function\n",
    "def nuts_sampler(init):\n",
    "    nuts_kernel = tfp.mcmc.NoUTurnSampler(\n",
    "        target_log_prob_fn=censored_poisbinom_loglike, \n",
    "        step_size=init_step_size,\n",
    "    )\n",
    "    adapt_nuts_kernel = tfp.mcmc.DualAveragingStepSizeAdaptation(\n",
    "        inner_kernel=nuts_kernel,\n",
    "        num_adaptation_steps=nuts_burnin,\n",
    "        step_size_getter_fn=lambda pkr: pkr.step_size,\n",
    "        log_accept_prob_getter_fn=lambda pkr: pkr.log_accept_ratio,\n",
    "        step_size_setter_fn=lambda pkr, new_step_size: pkr._replace(step_size=new_step_size)\n",
    "    )\n",
    "\n",
    "    samples = tfp.mcmc.sample_chain(\n",
    "        num_results=nuts_samples,\n",
    "        current_state=init,\n",
    "        kernel=adapt_nuts_kernel,\n",
    "        num_burnin_steps=nuts_burnin,\n",
    "        parallel_iterations=10,\n",
    "        trace_fn=None\n",
    "    )\n",
    "    return samples\n",
    "\n",
    "start = time.time()\n",
    "samples = nuts_sampler(init)\n",
    "print(f\"{time.time() - start:.02f} seconds elapsed\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorFlow (GPU)",
   "language": "python",
   "name": "tf-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
